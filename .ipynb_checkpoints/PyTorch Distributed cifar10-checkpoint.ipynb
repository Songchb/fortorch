{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import shutil\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.distributed as dist\n",
    "import torch.optim\n",
    "import torch.utils.data\n",
    "import torch.utils.data.distributed\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from utils import progress_bar\n",
    "\n",
    "# Module\n",
    "import googlenet\n",
    "\n",
    "parser = argparse.ArgumentParser(description='PyTorch CIFAR10 Traning')\n",
    "\n",
    "parser.add_argument('--lr', default=0.1, type=float, help='learning rate')\n",
    "parser.add_argument('--backend', default='gloo', type=str)\n",
    "parser.add_argument('--world-size', default=1, type=int, help='number of distributed processes (default=1)')\n",
    "parser.add_argument('--dist-url', type=str, help='url used to set up distributed training')\n",
    "parser.add_argument('--resume', '-r', action='store_true', help='resume from checkpoint')\n",
    "parser.add_argument('--epochs', default=3, type=int, metavar='N', help='number of total epochs to run')\n",
    "parser.add_argument('--rank', default=0, type=int, help='current node rank')\n",
    "args = parser.parse_args()\n",
    "\n",
    "args.distributed = args.world_size > 1\n",
    "args.use_cuda = torch.cuda.is_available()\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "print('===> training on: ', device)\n",
    "best_accuracy = 0\n",
    "start_epoch = 0\n",
    "\n",
    "# Data\n",
    "print('===> Preparing Data')\n",
    "transform_tran = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_tran)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=1)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=1, pin_memory=True)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "if args.resume:\n",
    "    print('===> Resuming from checkpoint...')\n",
    "    assert os.path.isdir('checkpoint'), 'Error: no checkpoint directory found!'\n",
    "\n",
    "    checkpoint = torch.load('./checkpoint/ckpt.t7')\n",
    "    net = checkpoint['net']\n",
    "    best_acc = checkpoint['acc']\n",
    "    start_epoch = checkpoint['epoch']\n",
    "else:\n",
    "    print('===> Building model...')\n",
    "    net = googlenet.GoogLeNet()\n",
    "\n",
    "if args.distributed:\n",
    "    print('===> Distributed Training Mode')\n",
    "    dist.init_process_group(backend=args.backend, init_method=args.dist_url, rank=args.rank, world_size=args.world_size)\n",
    "\n",
    "if args.distributed:\n",
    "    if args.use_cuda:\n",
    "        print('===> DistributedDataParallel')\n",
    "        net.to(device)\n",
    "        net = torch.nn.parallel.DistributedDataParallel(net)\n",
    "    else:\n",
    "        print('===> DistributedDataParallelCPU')\n",
    "        net = torch.nn.parallel.DistributedDataParallelCPU(net)\n",
    "else:\n",
    "    if args.use_cuda:\n",
    "        print('===> DataParallel')\n",
    "        net.to(device)\n",
    "        net = torch.nn.parallel.DataParallel(net)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss().cuda() if args.use_cuda else nn.CrossEntropyLoss() \n",
    "optimizer = torch.optim.SGD(net.parameters(), args.lr, momentum=0.9, weight_decay=5e-4)\n",
    "\n",
    "# Training\n",
    "\n",
    "def train(epoch):\n",
    "    print('\\nEpoch: %d' % epoch)\n",
    "    print('Train')\n",
    "    net.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    global best_accuracy\n",
    "\n",
    "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "        if args.use_cuda:\n",
    "            inputs, targets = inputs.to(device), targets.cuda(non_blocking=True)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets.data).cpu().sum()\n",
    "\n",
    "        progress_bar(batch_idx, len(trainloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)' % (train_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
    "        \n",
    "        # Save checkpoint.\n",
    "        acc = 100.*correct/total\n",
    "        if acc > best_accuracy:\n",
    "            print('\\nSaving..')\n",
    "            state = {\n",
    "                'net': net.module if args.use_cuda else net,\n",
    "                'acc': acc,\n",
    "                'epoch': epoch,\n",
    "            }\n",
    "            if not os.path.isdir('checkpoint'):\n",
    "                os.mkdir('checkpoint')\n",
    "            torch.save(state, './checkpoint/ckpt.t7')\n",
    "            best_accuracy = acc\n",
    "\n",
    "def test(epoch):\n",
    "    print('\\nTest')\n",
    "\n",
    "    global best_accuracy\n",
    "    net.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "        if args.use_cuda:\n",
    "            inputs, targets = inputs.to(device), targets.cuda(non_blocking=True)\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "\n",
    "        test_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets.data).cpu().sum()\n",
    "        progress_bar(batch_idx, len(trainloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)' % (test_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
    "\n",
    "    # Save checkpoint.\n",
    "    acc = 100.*correct/total\n",
    "    if acc > best_accuracy:\n",
    "        print('\\nSaving..')\n",
    "        state = {\n",
    "            'net': net.module if args.use_cuda else net,\n",
    "            'acc': acc,\n",
    "            'epoch': epoch,\n",
    "        }\n",
    "        if not os.path.isdir('checkpoint'):\n",
    "            os.mkdir('checkpoint')\n",
    "        torch.save(state, './checkpoint/ckpt.t7')\n",
    "        best_accuracy = acc\n",
    "\n",
    "def validate():\n",
    "    print('============================> Validating')\n",
    "    class_correct = list(0. for i in range(10))\n",
    "    class_total = list(0. for i in range(10))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            if args.use_cuda:\n",
    "                images, labels = images.to(device), labels.cuda(non_blocking=True)\n",
    " \n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            c = (predicted == labels).squeeze()\n",
    "            for i in range(4):\n",
    "                label = labels[i]\n",
    "                class_correct[label] += c[i].item()\n",
    "                class_total[label] += 1\n",
    "\n",
    "    for i in range(10):\n",
    "        print('Accuracy of %5s : %2d %%' % (classes[i], 100 * class_correct[i] / class_total[i]))\n",
    "    print('========================================')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    for epoch in range(start_epoch, start_epoch+args.epochs):\n",
    "        train(epoch)\n",
    "        test(epoch)\n",
    "        validate()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
